{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconhecimentos de Padrões\n",
    "\n",
    "## Alunos: Henrique Ricardo Figueira, Higor Celante\n",
    "## Dataset: sEMG for Basic Hand movements Data Set\n",
    "\n",
    "\n",
    "A base de dados utilizada tem as seguintes características:\n",
    "\n",
    "- Série Temporal\n",
    "- 2 canais EMG\n",
    "- 5 arquivos\n",
    "\n",
    "Datasets:\n",
    " - 6s = 2 homens e 2 mulheres na fixa dos 22 anos executaram os 6 movimentos 30 vezes cada, cada movimento sendo coletado por 6s.\n",
    " - 5s = 1 homem executou os 6 movimentos 100 vezes cada, por 5s cada movimento.\n",
    " \n",
    "Movimentos:\n",
    "\n",
    "- Esférico\n",
    "- Palma aberta\n",
    "- Lateral\n",
    "- Cilíndrico\n",
    "- Gancho\n",
    "- Pinça\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![movimentos](https://i.imgur.com/0faxxKu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "from librosa import stft\n",
    "from numpy import mean, sqrt, square, arange\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhos = [os.path.join(\"src\", nome) for nome in os.listdir(\"src\")]\n",
    "pessoas = []\n",
    "\n",
    "for essive in caminhos:\n",
    "    if essive != \"/novo.txt\":\n",
    "        mat = scipy.io.loadmat(essive)\n",
    "        tip = [mat['tip_ch1'], mat['tip_ch2']]\n",
    "        spher = [mat['spher_ch1'], mat['spher_ch2']]\n",
    "        palmar = [mat['palm_ch1'], mat['palm_ch2']]\n",
    "        lateral = [mat['lat_ch1'], mat['lat_ch2']]\n",
    "        cilindrical = [mat['cyl_ch1'], mat['cyl_ch2']]\n",
    "        hook = [mat['hook_ch1'], mat['hook_ch2']]\n",
    "        data = [tip, spher, palmar, lateral, cilindrical, hook]\n",
    "        data = np.array(data)\n",
    "        pessoas.append(data)  \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\" 6 movimentos,30 tentativas, 2 canais,  3000 coletas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando 1 dos Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataone = pessoas[2]\n",
    "dataone = np.array(dataone)\n",
    "dataone = np.swapaxes(dataone,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape após carregamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 6 movimentos, 30 tentativas, 2 canais,  3000 coletas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 30, 2, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(dataone.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sobreposicao:         150.0\n",
      "Salto:                350.0\n",
      "Tamanho do segmento:  500.0\n"
     ]
    }
   ],
   "source": [
    "datax = []\n",
    "segmentosize = (len(dataone[0,0,0,:]))/6\n",
    "salto = segmentosize * 0.7\n",
    "antpasso = segmentosize - salto\n",
    "\n",
    "\n",
    "print(\"Sobreposicao:        \", antpasso)\n",
    "print(\"Salto:               \",salto)\n",
    "print(\"Tamanho do segmento: \",segmentosize)\n",
    "\n",
    "\n",
    "for movimento in dataone:  \n",
    "    tentativs = []\n",
    "    for tentativas in movimento:\n",
    "        canals = []\n",
    "        for canal in tentativas:\n",
    "            \n",
    "            listinha = []\n",
    "            listinha.append(canal[350:850])\n",
    "            listinha.append(canal[700:1200])\n",
    "            listinha.append(canal[1050:1550])\n",
    "            listinha.append(canal[1400:1900])\n",
    "            listinha.append(canal[1750:2250])\n",
    "            listinha.append(canal[2100:2600])\n",
    "            canals.append(np.split(canal,6) + listinha)\n",
    "        tentativs.append(canals)\n",
    "    datax.append( tentativs)\n",
    "datax = np.array(datax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![segmentacao](https://i.imgur.com/rWhhCop.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape após segmentação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6 movimentos, 30 tentativas, 2 canais,  11 segmentos de 500 valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 30, 2, 12, 500)\n",
      "(30, 6, 2, 12, 500)\n"
     ]
    }
   ],
   "source": [
    "print(datax.shape)\n",
    "datax = np.swapaxes(datax, 0,1)\n",
    "print(datax.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domínio do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iemg = []\n",
    "rmslist = []\n",
    "varlist = []\n",
    "\n",
    "for movimento in datax:\n",
    "    listvar = []\n",
    "    listiemg = []\n",
    "    listrms = []\n",
    "    for tentativas in movimento:\n",
    "\n",
    "        for canal in tentativas:\n",
    "            #listseg = 0.0\n",
    "            segvar = []\n",
    "            segrms = []\n",
    "            segiemg = []\n",
    "\n",
    "\n",
    "            for segmento in canal:\n",
    "                \n",
    "                #MAV ACUM\n",
    "                mav = (abs(segmento.sum())/ 500 )\n",
    "                segiemg.append(mav)\n",
    "           \n",
    "\n",
    "                #RMS ACUM\n",
    "                rms = sqrt(mean(square(segmento)))\n",
    "                segrms.append(rms)\n",
    "                \n",
    "                #VAR ACUM               \n",
    "                VAR = np.var(segmento)\n",
    "                segvar.append(VAR)\n",
    "\n",
    "                \n",
    "                \n",
    "            #au = map(f, listseg)\n",
    "            #listiemg[segiemg])\n",
    "\n",
    "            listiemg.append(segiemg)\n",
    "            listrms.append(segrms)\n",
    "            listvar.append(segvar)\n",
    "    iemg.append(listiemg)\n",
    "    rmslist.append(listrms)\n",
    "    varlist.append(listvar)\n",
    "\n",
    "iemg = np.array(iemg)\n",
    "#iemg = iemg.reshape((6,660))\n",
    "rmslist = np.array(rmslist)\n",
    "#rmslist = rmslist.reshape((6,660))\n",
    "varlist = np.array(varlist)\n",
    "#varlist = varlist.reshape((6,660))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(iemg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 6, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(rmslist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 6, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(varlist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domínio da frequência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 30, 2, 11)\n",
      "(11, 2)\n",
      "(6, 60)\n",
      "(6, 60)\n",
      "(6, 120)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "print(datax[:,:,:,0:11].shape)\n",
    "psdf = []\n",
    "fmn = []\n",
    "fmd = []\n",
    "cont = 0\n",
    "allft = []\n",
    "for lvl1 in datax:\n",
    "    ffttemp = []\n",
    "    fmd_temp = []\n",
    "    fmn_temp = []\n",
    "    som_fmd = 0\n",
    "    som_fmn = 0\n",
    "    for lvl2 in lvl1:\n",
    "        for lvl3 in lvl2:\n",
    "            #, hop_length=150\n",
    "            if (cont < 11):\n",
    "                temp = np.abs(stft(lvl3[cont], n_fft=500,hop_length=350))\n",
    "                psd = welch(temp)\n",
    "                psdf.append(psd)\n",
    "                Fi = (cont * 500) / (2 * len(psd[1]))\n",
    "                cont+=1\n",
    "            for lvl3 in psd[1]:\n",
    "                som_fmd += lvl3.sum()\n",
    "                som_fmn += lvl3.sum()\n",
    "                \n",
    "            fmn_temp.append((Fi * som_fmn) / som_fmn)\n",
    "            fmd_temp.append(0.5 * som_fmd)\n",
    "            allfttemp = fmn_temp + fmd_temp\n",
    "    fmd_temp = np.array(fmd_temp)\n",
    "    fmd.append(fmd_temp)\n",
    "    fmn_temp = np.array(fmn_temp)\n",
    "    fmn.append(fmn_temp)\n",
    "    allft.append(allfttemp)\n",
    "    \n",
    "fmd = np.array(fmd)\n",
    "fmn = np.array(fmn)\n",
    "psdf = np.array(psdf)\n",
    "allft = np.array(allft)\n",
    "print(psdf.shape)\n",
    "print(fmd.shape)\n",
    "print(fmn.shape)\n",
    "print(allft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(psdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 60)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(fmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 60)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(fmn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Junção do FMN e FMD, MAV, RMS, VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 120)\n"
     ]
    }
   ],
   "source": [
    "#allft = allft * VARLIST [:,0:120]\n",
    "\n",
    "print(allft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import (brier_score_loss, precision_score, recall_score,f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2100)\n",
      "(12600, 1)\n"
     ]
    }
   ],
   "source": [
    "teste = np.concatenate((iemg, rmslist, varlist, fmn, fmd), axis =1)\n",
    "print(teste.shape)\n",
    "X = teste.reshape(12600,1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2100\n",
      "1\n",
      "4200\n",
      "2\n",
      "6300\n",
      "3\n",
      "8400\n",
      "4\n",
      "10500\n",
      "5\n",
      "12600\n",
      "0\n",
      "2100\n",
      "1\n",
      "4200\n",
      "2\n",
      "6300\n",
      "3\n",
      "8400\n",
      "4\n",
      "10500\n",
      "5\n",
      "12600\n",
      "0\n",
      "2100\n",
      "1\n",
      "4200\n",
      "2\n",
      "6300\n",
      "3\n",
      "8400\n",
      "4\n",
      "10500\n",
      "5\n",
      "12600\n",
      "0\n",
      "2100\n",
      "1\n",
      "4200\n",
      "2\n",
      "6300\n",
      "3\n",
      "8400\n",
      "4\n",
      "10500\n",
      "5\n",
      "12600\n",
      "0\n",
      "2100\n",
      "1\n",
      "4200\n",
      "2\n",
      "6300\n",
      "3\n",
      "8400\n",
      "4\n",
      "10500\n",
      "5\n",
      "12600\n",
      "0\n",
      "2100\n",
      "1\n",
      "4200\n",
      "2\n",
      "6300\n",
      "3\n",
      "8400\n",
      "4\n",
      "10500\n",
      "5\n",
      "12600\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "(6, 12600)\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "cont = 0\n",
    "\n",
    "\n",
    "cumy = []\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    y0 = []\n",
    "    cont = 0\n",
    "    for movimentos in teste:\n",
    "        \n",
    "        for sample in movimentos:\n",
    "            if(cont == i):\n",
    "                y0.append(1)\n",
    "\n",
    "            \n",
    "            else:\n",
    "                y0.append(2)\n",
    "        print(cont)\n",
    "        cont+=1\n",
    "        print(len(y0))\n",
    "    cumy.append(y0)\n",
    "print(cumy[cont-1][10500:])\n",
    "    \n",
    "\n",
    "cumy = np.array(cumy)\n",
    "print(cumy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = []\n",
    "#for lvl1 in teste:\n",
    "   #for lvl2 in lvl1:\n",
    "    #        y.append(lvl2)\n",
    "#y = np.array(y)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12600, 1)\n",
      "[2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "#X = X.swapaxes(0,1)\n",
    "\n",
    "print(X.shape)\n",
    "#print(y.shape)\n",
    "print(cumy[1][655:665])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12600,)\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.001 C: 1\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.001 C: 10\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.001 C: 100\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.001 C: 1000\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.01 C: 1\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.01 C: 10\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.01 C: 100\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.01 C: 1000\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.1 C: 1\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.1 C: 10\n",
      "acuracia: 83.25396825396825 kernel: rbf gamma: 0.1 C: 100\n",
      "acuracia: 83.2936507936508 kernel: rbf gamma: 0.1 C: 1000\n",
      "\n",
      "LDA acuracia: 83.25396825396825\n",
      "(12600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia: 84.92063492063492 kernel: rbf gamma: 0.001 C: 1\n",
      "acuracia: 84.92063492063492 kernel: rbf gamma: 0.001 C: 10\n",
      "acuracia: 87.97619047619048 kernel: rbf gamma: 0.001 C: 100\n",
      "acuracia: 88.17460317460318 kernel: rbf gamma: 0.001 C: 1000\n",
      "acuracia: 87.65873015873015 kernel: rbf gamma: 0.01 C: 1\n",
      "acuracia: 87.10317460317461 kernel: rbf gamma: 0.01 C: 10\n",
      "acuracia: 88.29365079365078 kernel: rbf gamma: 0.01 C: 100\n",
      "acuracia: 87.97619047619048 kernel: rbf gamma: 0.01 C: 1000\n",
      "acuracia: 88.65079365079364 kernel: rbf gamma: 0.1 C: 1\n",
      "acuracia: 88.76984126984127 kernel: rbf gamma: 0.1 C: 10\n",
      "acuracia: 88.84920634920634 kernel: rbf gamma: 0.1 C: 100\n",
      "acuracia: 88.84920634920634 kernel: rbf gamma: 0.1 C: 1000\n",
      "\n",
      "LDA acuracia: 84.92063492063492\n",
      "(12600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.001 C: 1\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.001 C: 10\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.001 C: 100\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.001 C: 1000\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.01 C: 1\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.01 C: 10\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.01 C: 100\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.01 C: 1000\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.1 C: 1\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.1 C: 10\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.1 C: 100\n",
      "acuracia: 83.01587301587303 kernel: rbf gamma: 0.1 C: 1000\n",
      "\n",
      "LDA acuracia: 83.01587301587303\n",
      "(12600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.001 C: 1\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.001 C: 10\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.001 C: 100\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.001 C: 1000\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.01 C: 1\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.01 C: 10\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.01 C: 100\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.01 C: 1000\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.1 C: 1\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.1 C: 10\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.1 C: 100\n",
      "acuracia: 82.65873015873015 kernel: rbf gamma: 0.1 C: 1000\n",
      "\n",
      "LDA acuracia: 82.65873015873015\n",
      "(12600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.001 C: 1\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.001 C: 10\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.001 C: 100\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.001 C: 1000\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.01 C: 1\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.01 C: 10\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.01 C: 100\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.01 C: 1000\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.1 C: 1\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.1 C: 10\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.1 C: 100\n",
      "acuracia: 82.57936507936508 kernel: rbf gamma: 0.1 C: 1000\n",
      "\n",
      "LDA acuracia: 82.57936507936508\n",
      "(12600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.001 C: 1\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.001 C: 10\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.001 C: 100\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.001 C: 1000\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.01 C: 1\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.01 C: 10\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.01 C: 100\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.01 C: 1000\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.1 C: 1\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.1 C: 10\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.1 C: 100\n",
      "acuracia: 83.80952380952381 kernel: rbf gamma: 0.1 C: 1000\n",
      "\n",
      "LDA acuracia: 83.80952380952381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/home/higor/.local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X)\n",
    "ss.transform(X)\n",
    "for ypsilons in cumy:\n",
    "    print(ypsilons.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, ypsilons, test_size = 0.2, shuffle=True)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y0, test_size=0.33, random_state=42)\n",
    "    #clf = OutputCodeClassifier(LinearSVC(random_state=0), code_size=2, random_state=0)\n",
    "    #clf.fit(X_train, y_train).predict(X_test) \n",
    "    #y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "    #print(y_pred.shape)\n",
    "    #print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "    for kernel in ['rbf']:#, 'linear']:\n",
    "        for gamma in [0.001, 0.01, 0.1]:\n",
    "            for C in [1, 10, 100, 1000]:\n",
    "                classificador = []\n",
    "                classificador = svm.SVC(gamma=gamma, C=C, kernel=kernel).fit(X_train, y_train)\n",
    "                print('acuracia:', (classificador.score(X_test, y_test)) * 100, 'kernel:', kernel, 'gamma:', gamma, 'C:', C)\n",
    "            \n",
    "\n",
    "    cls = []\n",
    "    cls = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto', n_components=7).fit(X_train, y_train)\n",
    "    print('\\nLDA acuracia:', cls.score(X_test, y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "\n",
    "X = teste\n",
    "y = [\"movimento1\", \"movimento2\", \"movimento3\", \"movimento4\", \"movimento5\", \"movimento6\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "clf.fit(X, y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movimento1' 'movimento2']\n",
      "[[1.68089912e-01 1.68753008e-01 1.71609190e-01 ... 7.96965344e+04\n",
      "  8.09700791e+04 8.22436237e+04]\n",
      " [1.74516332e-01 1.41415272e-01 1.74720424e-01 ... 7.38655907e+04\n",
      "  7.51391354e+04 7.64126801e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X_test))\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
